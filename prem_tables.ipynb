{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aca0d37",
   "metadata": {},
   "source": [
    "# Extracting Premier League tables from wikipedia\n",
    "\n",
    "I have also done this in R. Wanted to show methods using Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "07fbe9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup years and seasons \n",
    "years = np.arange(1992, 2025, 1)\n",
    "\n",
    "years_sub = [str(y)[2:] for y in years + 1]\n",
    "\n",
    "season = [f\"{s}-{s + 1}\" for s in years]\n",
    "\n",
    "# vectors for setting up links \n",
    "fa_1 = np.arange(0, 7, 1)\n",
    "nfa_1 = 7\n",
    "fa_2 = np.arange(8, 15, 1)\n",
    "nfa_2 = np.arange(15, len(years))\n",
    "\n",
    "# construct the urls (list comp + list concat)\n",
    "# similar to list = [list1] + [list2] + [list3] + [list4]\n",
    "url_list = (\n",
    "    [f\"https://en.wikipedia.org/wiki/{years[i]}%E2%80%93{years_sub[i]}_FA_Premier_League\" for i in fa_1] +\n",
    "    [f\"https://en.wikipedia.org/wiki/{years[nfa_1]}%E2%80%93{years_sub[nfa_1]}_Premier_League\"] +\n",
    "    [f\"https://en.wikipedia.org/wiki/{years[i]}%E2%80%93{years_sub[i]}_FA_Premier_League\" for i in fa_2] +\n",
    "    [f\"https://en.wikipedia.org/wiki/{years[i]}%E2%80%93{years_sub[i]}_Premier_League\" for i in nfa_2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe81f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making custom bot to be nice to wikipedia\n",
    "headers = {\n",
    "    'User-Agent': 'MyBot/1.0 (andrewmoles2@gmail.com)'\n",
    "}\n",
    "\n",
    "# loop through links to pull all tables on each page\n",
    "wiki_tables = []\n",
    "\n",
    "for url in url_list:\n",
    "    r = requests.get(url, headers=headers)\n",
    "    time.sleep(1)\n",
    "    df = pd.read_html(io.StringIO(r.text))\n",
    "    wiki_tables.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3096f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract just the league tables - they all have 11 columns\n",
    "# note you can do this manually but this is the better programmic way! \n",
    "league_tables = []\n",
    "\n",
    "for tables in wiki_tables:\n",
    "    filt = [len(c.columns) for c in tables]\n",
    "    filt_index = [n for n, name in enumerate(filt) if name == 11]\n",
    "    if filt_index:\n",
    "        league_tables.append(tables[filt_index[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add season as column for each data frame\n",
    "for s in range(0, len(league_tables)):\n",
    "    league_tables[s].insert(11, \"season\", season[s])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix col names for 19-20\n",
    "league_tables[27] = league_tables[27].rename(columns={'Teamvte': 'Team'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba252e",
   "metadata": {},
   "source": [
    "Things left to do:\n",
    "\n",
    "Clean each data frame in the list doing\n",
    "  - Clean the names using janitor\n",
    "  - remove the [] and other weird string issues\n",
    "  - remove whitespace for teams\n",
    "  - make sure pts is int\n",
    "  - redo the gd column so it is not a string but an int. Previously easiest way was to just do a calculation on gf-ga\n",
    "\n",
    "make a combined data frame and save\n",
    "save each season from the list. Ideally this would be controlled so you create the file in python (checking if it exists) then write out each one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc63f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
